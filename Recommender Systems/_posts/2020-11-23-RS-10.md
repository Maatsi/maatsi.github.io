---
title: "Recommender systems (Part 3): Hybrid Recommenders"
tags: [Recommender Systems]
categories:
  - Recommender Systems
date: 2020-11-23
---




## **Recommender systems (Part 3): Hybrid Recommenders**

**Hybridization**
  - Several algorithms giving different results – way to combine several algorithms
  - In this note:
    - How to put it next to each other to decide how you going to
        hybridize
    - Fundamental models behind the recommendations
  - Second part - Actual hybridization method
  - Group
    - We have individual model and how to decide what's the best for
        the group
    - Aggregation strategies


**Content based filtering**
  - Need to know about the user and the content – represented in
    some form
  - Using this, you are giving the user what they might like
  - E.g. checking discovery modules
      - What topic, what students are interested etc


**Collaborative filtering**
  - Only if you have collected how other people have interacted and made
    choices
  - Based on what other people have chosen, it helps you recommend it –
    no need to know about the content


**Sources for recommendations**
  - ![image](https://user-images.githubusercontent.com/33334078/95709168-1104f800-0c99-11eb-84f2-4f31bf172e2c.png)
  - Now taking the decision on which algorithm to use – its not straightforward
    what to choose.
  - Do you have enough input?
  - Think what sources you have – social, individual, and the
    content
  - Social
    - Rating, tags – what they’ve said
    - Reviews – what people liked and disliked
    - Behaviours – aspects of what the watched, voted liked etc
    - Demographics – age and where from, about the crowd
    - Context – where was the movie watched, as a group etc


  - **Bare minimum to run social filtering - is the opinion**
  - Individual – what do you know about individuals
    - Opinions – rate a few movies, and give more precise recommendations
    - Behaviour – on the weekends, they listen to relaxing jazz
    - Demographics – age, nationalities, place
    - Requirements
      - Query - what they are looking for
      - Constraints - they have mobile and desktop etc
      - Preferences – customisable model
      - Context – how much do we know and how reliable is this
  - Content based filtering – **minimum is the behaviour or the
    demographic**


  - **Content**
    - Item – I need to haves some description – paper- where, by who,
      how long etc
    - Domain knowledge – about the world
      - What sources do I have and how reliable are they
      - Temporarily dependent data – like music taste etc, when
        you’ve been to the hotel and it still recommends you it


**Recommender algorithms – key**
- Need to have a systematic approach on combining different ones
- What are the key sources ??
- When I'm developing, what are the features I should bear in mind
  - **Background data** – before you start any of the processing –
    collect background info
  - **Input data** – when the user is interacting with the system,
    what data I capture about the user. What does user need to
    communicate in the system
  - **Algorithm** – combining that input data and background data to
    arrive at suggestions
- Should be able to: describe what background data, input data and
algorithms you would use

**Comparing recommender algorithms**
- ![image](https://user-images.githubusercontent.com/33334078/95709202-2417c800-0c99-11eb-9c59-382aa1dfc854.png)
- Utility – what is the benefit for the user? And it recommends the most efficient or the best choice
  - Best decision – important for doctors when diagnosing
  - People be happy


**Pros and cons of recommender algorithms**
- ![image](https://user-images.githubusercontent.com/33334078/95709218-2c700300-0c99-11eb-9a6c-f924ad5a92e4.png)
- Algorithm in particular context and you need to point out the strength and weakness of the algorithm
  - K - Gray sheep problem – user does not fall in any existing cliques
    of users
  - M – need to recalculate the thing again and again

**Hybrid filtering – netfiix video**
- Netflix's target was to ensure **precision** – to fulfil that 10% gap
- Everything can be reduced into data, which is turned into mathematical models to predict movies you like
- System relies on __collaborative filtering__ – user -> mathematical models which spits out recommendations
- 10% improvement over current model
- Method
  - Analysed the dataset – one rating per user?
  - Looking for patterns in the data
  - Singular value decomposition- characterises each movie and user into vectors, in 2D
- Applying many different models and averaging it gave the best performance to reach the 10%
- One problem – some movies are very polarising with diff
  variance of rating
    - Napoleon dynamite – 1 and 5 rating


- **Average of 800 different algorithms**
  - When you have a massive population of algorithms, but even then, it might not be
    suitable for the problem scope
  - They’ve analysed the strengths and weaknesses of each algorithms to use it accordingly


**How to combine? Hybridisation algorithms**
  - For each algorithm, it produces different recommendation – so how do
    we combine them?
  - Netflix took 800 and took the average in the second round. In the
    first round they analysed all the algorithms
  - ![image](https://user-images.githubusercontent.com/33334078/95709236-3560d480-0c99-11eb-903b-93293e0ddf68.png)



1.  **Weighted**
  - **The scores (or votes) of several recommendation techniques are combined together to produce a single recommendation.**
  - Weight – gradually adjusts the weighting as predictions about user ratings are confirmed or disconfirmed.
  - For each of the algorithm, we have weights attached to it. We need to examine which works in which condition
  - If we have the weights, it simply computes the **weighted sum**  
![image](https://user-images.githubusercontent.com/33334078/95709270-47427780-0c99-11eb-9fec-272263472294.png)

  | Pro | Cons |
  |----|----|
  | All of the system’s capabilities are brought to bear on the recommendation process in a straightforward way and it is easy to perform post-hoc credit assignment and adjust the hybrid accordingly. | Relative value of different techniques is uniform – so items with smaller raters will be weaker |


2.  **Switching**
  - **The system switches between recommendation techniques depending on the current situation.**
  - Switching – you ask for an opinion and you decide to switch base on
    different groups in different context
  - Important to know what exactly is the context – what media, time,
    item user is using?
  - We have different algorithms and depending on the user and the item, for one
    user we recommend R1 and for another item we recommend R2 or Rn.
  - Crucial is that we need a very good understanding of how each algorithms
    work and which is the best in the current context  
    ![image](https://user-images.githubusercontent.com/33334078/95709295-4f9ab280-0c99-11eb-897b-a9ce09bc83c9.png)

  | Pro | Cons |
  |----|----|
  | The ability to cross genres that are not semantically close, but still relevant. | The ramp up problem - the short term model is always used first and other comes in to play when it fails -> this introduces additional complexity as switching criteria must be determined


3.  **Mixed**
  - **Recommendations from several different recommenders are presented at the same time**
  - Users can make their own choice – they see recommendations from
    content based, knowledge based etc.
  - Different algorithms return different values, and for this user, we show R1 and R2
  - Crucial is to explain to the user, the results
  - Another crucial factor is that the recommendations shouldn’t be too controversial - coherence in recommendations  
  ![image](https://user-images.githubusercontent.com/33334078/95709306-57f2ed80-0c99-11eb-8e14-df3cef41d5ea.png)

  | Pro | Cons |
  |----|----|
  | Avoids the cold start problem, as it has niche finding property that can bring in new items that a strict focus on content would eliminate.|


4.  **Feature combination**
  - **Features from different recommendation data sources are thrown together into a single recommendation algorithm.**
  - We are coming up with one value, but we use different data to come up with
    that one value
  - New algorithm which can combine features from all the outputs
    - One is weighted output.
    - More complicated to look at what feature is the strongest for that part
      - Click? Ratings?
    - Then you use the strongest feature from each one, and you put them in a one combined algorithm to come up with a better algorithm   
![image](https://user-images.githubusercontent.com/33334078/95709322-5fb29200-0c99-11eb-87c0-11a71173f5ee.png)

  | Pro | Cons |
  |----|----|
  | The feature combination hybrid lets the system consider collaborative data without relying on it exclusively -> reduces the sensitivity of the system to the number of users who have rated an item. | |


5.  **Cascade**
  - **One recommender refines the recommendations given by another.**
  - Run one algorithm, and get the output, then you take it and pass it onto
    different algorithm, until you get the refined version
  - Run A1, then you get R1. Then put R1 to A2. Then R2 is put into A3
    etc
  - Usually works when we are considering all possible items, rather
    than one single item until we come up with most refined  
    ![image](https://user-images.githubusercontent.com/33334078/95709336-680acd00-0c99-11eb-91ae-8c62592e5694.png)

  | Pro | Cons |
  |----|----|
  | More efficient as it allows the system to avoid employing the second, lower-priority, technique on items that are already well-differentiated by the first method → more efficient and tolerant to the noise of low priority techniques |


6.  **Feature augmentation**
  - **Output from one technique is used as an input feature to another.**
  - Quite similar w/ cascade
  - We look at the features of each algorithm we are going to use
  - Take A1, and it gives R1. Then for the second round, we have different features.
    But we still bring in R1 in addition to the feature \! so it acts as
    an additional feature so that A2 has **broader feature scope**    
    ![image](https://user-images.githubusercontent.com/33334078/99926316-a27d8480-2d84-11eb-99b2-e49b24e61778.png)

  | Pro | Cons |
  |---- | ----|
  | It offers a way to improve the performance of a core system without modifying it | |


7.  **Meta level**
  - **The model learned by one recommender is used as an input to another. Entire method becomes the input**
  - Taking output of one algorithm and put it to another
  - A1 gets R1. Also look at values from a set of items. Then you used
    that in some way as additional feature, input etc meta level, because
    you need to think how the R1 is going to be used cleverly as an input
    of A2
    ![image](https://user-images.githubusercontent.com/33334078/99926327-ac06ec80-2d84-11eb-8453-9ad71daae9b8.png)  

  | Pro | Cons |
  |----|----|
  | The learned model is a compressed representation of user’s interest and a collaborative mechanism that follows can operate on this information-dense representation | |


**Summary**
  - **Comparison between methods** – identify pros and cons for each
    method in particular situations
  - **Key features of recommender algorithms**
    - Before you decide which algorithm to use, need to look at the input
    - Background data, input data, algorithm
  - **Hybridisation methods** – identify an appropriate hybridisation
  method to maximise the pros and minimise the cons of the combined
  methods given a particular app
    - Each of the hybridisation becomes a method on its own.
  - **Research trends**
    - Active research field
    - Research innovation route quite fast
